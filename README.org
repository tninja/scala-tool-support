#+TITLE: Scala spark-shell mode
#+DATE: <2016-06-12 Sun>
#+AUTHOR: Kang Tu
#+EMAIL: tninja@Pengs-MacBook-Pro.local
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline
#+OPTIONS: author:t c:nil creator:comment d:(not "LOGBOOK") date:t
#+OPTIONS: e:t email:nil f:t inline:t num:t p:nil pri:nil stat:t
#+OPTIONS: tags:t tasks:t tex:t timestamp:t toc:nil todo:t |:t
#+CREATOR: Emacs 24.5.1 (Org mode 8.2.10)
#+DESCRIPTION:
#+EXCLUDE_TAGS: noexport
#+KEYWORDS:
#+LANGUAGE: en
#+SELECT_TAGS: export

* Motiviation
 
Spark-shell is a good place to develop and test spark / spark sql code interactively. As a data scientist / engineer, I wish I have a editor support for that. I hope the editor would looks like RStudio / emacs ESS / ipython notebook. Not able to find an available on online, I made a slightly change to scala-mode (from https://github.com/scala/scala-tool-support) to support interactive spark script development with spark-shell.

* Features

** scala-mode for spark-shell

- Features from scala-mode like keyword highlight etc
- Interactive spark script development, with ess / R-mode like key-binding

** literature programming support with org-mode

- Can run code block and print result to org document as an org-babel plugin

* Install / configuration

Requirement: emacs 24.5 and org-mode version >= 8.2.10

** Basic support

You can copy over tool-support/emacs to some place, and put the following code to your .emacs to load them

#+name: load
#+begin_src elisp :eval never
  (progn
    (cd "<<path-to-scala-spark-mode-elisp-dir>>")
    (normal-top-level-add-subdirs-to-load-path))

  (require 'scala-mode)
#+end_src

*** Modify spark-shell launch command

You can modify the spark-shell to some other thing to load your own jar and add your own start configuration like --num-executors, etc by redefine scala-interpreter

#+name: launcher-config
#+begin_src elisp :eval never
  (defcustom scala-interpreter "spark-shell"
    "The interpreter that `run-scala' should run. This should
   be a program in your PATH or the full pathname of the scala interpreter."
    :type 'string
    :group 'scala-mode-inf)
#+end_src

In a file buffer with .scala or .spark suffix, M-x scala-run-scala will open an spark-shell buffer.

*** Send code and eval them in the spark-shell buffer

- Line / block / region / buffer evaluation.
- The key-binding is ess / R-mode flavor

#+name: key-binding
#+begin_src elisp :eval never
  (progn (define-key scala-mode-map "\C-c\C-i" 'scala-run-scala)
         (define-key scala-mode-map "\C-c\C-r" 'scala-eval-region)
         (define-key scala-mode-map "\C-c\C-j" 'scala-eval-line)
         (define-key scala-mode-map "\C-c\C-c" 'scala-eval-block)
         (define-key scala-mode-map "\C-c\C-b" 'scala-eval-buffer)
         (define-key scala-mode-map "\C-c\C-d" 'scala-eval-definition)
         (define-key scala-mode-map "\C-c\C-z" 'scala-switch-to-interpreter))
#+end_src

** Literature programming setup

Add the spark-shell language support to your org-babel-load-languages list, like this:

#+name: babel-config
#+begin_src elisp :eval never
  (org-babel-do-load-languages
   'org-babel-load-languages
   '((R . t)
     (spark-shell . t)
     (python . t)
     (org . t))
  )
#+end_src

[[file:helloworld.org][Here]] goes an spark-shell literature programming example.

* TODO Future Tasks [0/1]

** TODO Add code to handle output of spark-shell code chunk into a org-table
